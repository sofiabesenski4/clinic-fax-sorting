"""
Created: Feb 9th 2018
Sofia Besenski

to run : $python3 main.py --if <DIRECTORY NAME CONTAINING PDFs> --of <Directory name to output the results to>
							--db <name of the postgresql database to reference> --t <table name where the patients are contained>

This is the script which will iterate through each test file, processing it through tesseract ocr,
and then feeding the text into a java CoreNLPNER program to annotate the names of people in the medical letter,
and then reference the database where the patient files are stored in hopes of finding a patient match via PHN. DOB and/or partial name

there must be a stanford corenlp server running on the port 9000, and this will communicate
with that server, returning the output of the annotations.

The following command will start the server, from inside the corenlp folder:

NOTE: we need to specify enough ram to use in by stating -mx4g, since -mx2g will usually go over the memory usage
java -mx4g -cp "*" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -annotators "tokenize,ssplit,pos,lemma,parse,ner" -port 9000 -timeout 500000

PROGRAM FLOW:

updated Jun 1 2018
input-> directory containing the pdf documents

for all pdfs in directory:
	-convert pdf to jpg image using pdf2img module
	-enter jpg into pytesseract ocr engine to retrieve text

	-input text into StanfordCoreNLP Server running on port 9000, and annotate the text with Named Entity Recognition
	-filter through the annotations and store PERSON, DATE, and NUMBER elements

	-use precompiled regex to convert all the dates into a standardized format
	-use regex to determine which numbers could represent a PHN
	-make a connection with a database on the local machine, containing the table "patients" with columns:
		PATIENT HEALTH NUMBER, FIRST_NAME, LAST_NAME, DATE OF BIRTH
	-while we havent yet found a patient match and we havent checked each orientation
		-attempt to find all matches of PHNs and DOBs found using NER, corresponding to patient entries in the database
		-rotate the image to account for documents which were rotated by 90, 180, and 270 degrees
	-store all the names, dates, and numbers in text files in the Test_Results folder





"""
from shutil import copyfile
#using pytesseract as the ocr engine
import pytesseract
##using opencv to feed image input into tesseract
import cv2
import PIL
import os
#PIL is the python imaging library, used by opencv
from PIL import *
#PIL uses numpy to represent images
import numpy as np
from pdf2image import convert_from_path, convert_from_bytes
from stanfordcorenlp import StanfordCoreNLP
#import db_interaction
import db_interaction
import logging
import json
import sys
import re
import os
import argparse
from enum import Enum
import datetime
#user defined modules
import Interact_with_Server as interact
import PDF_To_TXT as p2t
import time
import gc
import date_extractor
#initializing a dictionary to simplify recognizing the different date formats:
#DATE_MODES = {"DDMMYYYY":1,"MMDDYYYY":2,"YYYYMMDD":3}

"""
FUNCTION: get_pdf_paths(directory_name, pdf_paths)
DESCRIPTION: A function which looks into the folder specified in cmd line argument, and returns a list of
			all files ending with ".pdf". If there is subfolders, they will recursively be checked for more pdf files, and
			their paths will be added to the output list
INPUT: string - directory name: the directory where the test/input pdf files are being stored. Should be contained within the pwd
	   list of strings - pdf_paths: by default is an empty list. this is the list which is to be returned by the function.
OUTPUT: list of Path objects - pdf_paths: a list of path objects which point to the pdf files used for input
"""
def get_pdf_paths(directory_name, pdf_paths = []):

	for file_name in os.listdir(directory_name):
		if file_name.endswith(".pdf"):
			pdf_paths.append(os.path.join(directory_name, file_name))
		elif os.path.isdir(os.path.join(directory_name, file_name)):
			print("directory: " + file_name)
			pdf_paths =get_pdf_paths(os.path.join(directory_name,file_name),pdf_paths)
	return pdf_paths

"""
FUNCTION:  PHN_identifier(num_list, regex_pattern)
DESCRIPTION: a function which iterates through a list of numbers (found in the document), replacing special space characters (\xa0) with normal spaces
			and looks for 10 digit numbers (optionally separated by some delimiters) which could represent PHNs in an input document
INPUT:  num_list: a list of strings generated by CoreNLP when parsing through the text.
OUTPUT: Verified and formatted strings which could represent real PHNs in a given document. Contains no duplicates.
"""
def PHN_identifier(num_list, regex_pattern):
	temp_list =[re.search(regex_pattern, element).group(0).replace(u"\xa0","") for element in num_list if re.search(regex_pattern, element)]
	temp_list = [(''.join(i for i in s if i.isdigit())) for s in temp_list]
	temp_set = set(temp_list)
	temp_list = list(temp_set)
	return temp_list
	#Notes on the regex pattern:
	#so we would prioritize finding an entire PHN with no spaces/etc in it, represented by the \d{10}
	#then we allow 10 occurences o	f a digit and any other delimiting character that is not a number or a new line
	#but also with a negative lookahead, so it will not match if there is a digit occuring after this second half of the or statement
	# prioritizing matches which have fewer delimiting characters
"""
FUNCTION: strip_dates(date_list, regex_pattern,valid_dates, DDMMYYYY, YYYYMMDD , MMDDYYYY):
DESCRIPTION: a function that takes a list of strings representing characters which could be considered dates in a given document,
			 ie: <2digits> - <2 digits> - <4 digits> could represent DDMMYYYY or MMDDYYYY, converts them into a standard form tuple(year,month,day)
			 and removes any trailing or leading characters which do not follow the form specifed by the booleans DDMMYYYY, YYYYMMDD, MMDDYYYY.
			 The dates can also contain the strings defined in month_dict, which represent the english words/abrev.s for the different months

INPUT: date_list- list of strings generated by regex parsing and CoreNLP, meant to contain  substrings in a document which could represent dates
				considering that they are in a "datelike" format. Determined by CoreNLP and the regex patterns used in the function find_dates()
		regex_pattern - a string regex pattern which is used to "cookie cutter" the year/month/day in each of the date strings in date_list
		valid_dates - a list of dates which is verified and in the standard form we are using (tuple of  ints (year,month,day)).
		DDMMYYYY,YYYYMMDD,MMDDYYYY - all booleans representing which date format we are currently considering in our function.
									-only one of these should be set to True, and otherwise unexpected results may occur
OUTPUT: valid_dates: list of integer tuples of the form (year, month, day) representing the extracted tuples which are of the form specified by the booleans.
					 NOTE: they are not datetime objects, and the ranges of their values are not checked to be valid. Errors will be thrown if
					 they are directly converted to datetime objects because of their potential dates being out of range, ie: month=13
"""

def strip_dates(date_list, regex_pattern,valid_dates, DDMMYYYY, YYYYMMDD , MMDDYYYY):
	# pattern DDMMYYYY_date_strip should strip away any unnecessary numbers, before or after a date.
	#ie: "2 1995 May-10" could be annotated as a date if the OCR recognized "Page 2 1995 May-10" in the pdf
	#it accounts for dates which would be of the form DD MM YYYY or MM DD YYYY where the month can be 2 dig number or it can be the full month name
	# pattern YYYYMMDD_date_strip accounts for dates where the year appears first


	month_dict = {"January":1,"February":2,"March":3,"April":4,"May":5,"June":6,"July":7,"August":8,"September":9,"October":10,"November":11,"December":12,
				"Jan":1,"Feb":2,"Mar":3,"Apr":4,"May":5,"Jun":6,"Jul":7,"Aug":8,"Sep":9,"Oct":10,"Nov":11,"Dec":12,"1":1,
				"2":2,"3":3,"4":4,"5":5,"6":6,"7":7,"8":8,"9":9,"10":10,"11":11,"12":12,"01":1,
				"02":2,"03":3,"04":4,"05":5,"06":6,"07":7,"08":8,"09":9,"10":10,"11":11,"12":12}

	if DDMMYYYY:
		#print("DDMMYYYY")
		print(str(valid_dates))
		[valid_dates.append((re.search(regex_pattern, element).group(4),month_dict[re.search(regex_pattern, element).group(3)],regex_pattern.search(element).group(2))) for element in date_list if (re.search(regex_pattern, element) and re.search(regex_pattern, element).group(3) in month_dict)]

	elif YYYYMMDD:
		#print("YYYYMMDD")
		[valid_dates.append((re.search(regex_pattern, element).group(2),month_dict[re.search(regex_pattern, element).group(3)],regex_pattern.search(element).group(4))) for element in date_list if (re.search(regex_pattern, element) and re.search(regex_pattern, element).group(3) in month_dict) ]
		#print(str(valid_dates))
	elif MMDDYYYY:
		#print("MMDDYYYY")
		[valid_dates.append((re.search(regex_pattern, element).group(4),month_dict[re.search(regex_pattern, element).group(2)],regex_pattern.search(element).group(3))) for element in date_list if (re.search(regex_pattern, element) and re.search(regex_pattern, element).group(2) in month_dict)]
		#print(str(valid_dates))
	return valid_dates

"""
FUNCTION: find_dates(text, regex_pattern, valid_dates, DDMMYYYY, YYYYMMDD, MMDDYYYY)
DESCRIPTION: a regex parser which parses a body of text(string) specified in the input as "text". This function is meant to catch/search for any
			of the dates which the CoreNLP parsing did not discover, and returns a list of substrings which could contain the dates used to identify the
			correct patient subject of a given document
INPUT: text- string, generated by the PDF to Text implementation in another module.
	   regex_pattern, a compiled regex pattern which is used to search through the text for dates
	   valid_dates, a list of dates which has already been checked for formatting and standardized into a tuple of ints format (year,month,day)
	   DDMMYYYY, YYYYMMDD, MMDDYYYY: all boolean variables representing which date format we are looking for during this function call.
OUTPUT:
		valid_dates: a list of tuples ints (year,month,day) which have been found in the body of text during this round of regex
NOTES: room for improvement here. We should check all formats in this function, removing the need for the format specifier which could be
		confused in the process leading to missed dates/not finding the correct patient date.
"""

def find_dates(text, regex_pattern,valid_dates, DDMMYYYY, YYYYMMDD , MMDDYYYY):
	# pattern DDMMYYYY_date_strip should strip away any unnecessary numbers, before or after a date.
	#ie: "2 1995 May-10" could be annotated as a date if the OCR recognized "Page 2 1995 May-10" in the pdf
	#it accounts for dates which would be of the form DD MM YYYY or MM DD YYYY where the month can be 2 dig number or it can be the full month name
	# pattern YYYYMMDD_date_strip accounts for dates where the year appears first

	month_dict = {"January":1,"February":2,"March":3,"April":4,"May":5,"June":6,"July":7,"August":8,"September":9,"October":10,"November":11,"December":12,
				"Jan":1,"Feb":2,"Mar":3,"Apr":4,"May":5,"Jun":6,"Jul":7,"Aug":8,"Sep":9,"Oct":10,"Nov":11,"Dec":12,"1":1,
				"2":2,"3":3,"4":4,"5":5,"6":6,"7":7,"8":8,"9":9,"10":10,"11":11,"12":12,"01":1,
				"02":2,"03":3,"04":4,"05":5,"06":6,"07":7,"08":8,"09":9,"10":10,"11":11,"12":12}

	if DDMMYYYY:
		#print("DDMMYYYY")
		#print(regex_pattern.findall(text))
		[valid_dates.append((element[3],month_dict[element[2]],element[1])) for element in regex_pattern.findall(text) if element[2] in month_dict]
		#print(str(valid_dates))
	elif YYYYMMDD:
		#print("YYYYMMDD")
		#print(regex_pattern.findall(text))
		[valid_dates.append((element[1],month_dict[element[2]],element[3])) for element in regex_pattern.findall(text) if element[2] in month_dict]
		#print(str(valid_dates))
	elif MMDDYYYY:
		#print("MMDDYYYY")
		#print(regex_pattern.findall(text))
		[valid_dates.append((element[3],month_dict[element[1]],element[2])) for element in regex_pattern.findall(text) if element[1] in month_dict]
		#print(str(valid_dates))

	return valid_dates


	"""
Function: patient_hypothesis(matches)
DESCRIPTION: a function which takes in a tuple of lists containing tuples, so a 3D list-like datastructure, and outputs a "match rating" A,B,C,D,F along with
			 the hypothesized patient tuple (PHN,first_name,last_name,DOB datetime object) belonging to the decided rating.
			 Will also output "Multiple matches found" if there are more than one patient who has been correctly identified according to the highest match rating
			 discovered in a document.
INPUT:
	a tuple of lists of tuples: Each of the lists matches is a list of patient tuples, who matched in this category
	(A matches:[(PHN,first_name,last_name,DOB),(),.....],B matches:[().....],C matches: [().....],D matches: [()......])
	matches is formatted in such a way that the data can be parsed, where the first non-empty list of matches represents the match found with the highest chance of correctness

OUTPUT:
	a tuple: (Status, Match/None)
	status = "Multiple Matches of X" or "A/B/C/D/F"
	Match is the complete patient entry in the database corresponding to the highest rated match(es) found.

	"""
def patient_hypothesis(matches):
	#if there is at least one match, then find the highest rating match(es) and return them as the most likely patient
	#print(str(matches))
	if matches[0] or matches[1] or matches[2] or matches[3] or matches[4]:
		if matches[0] and len(matches[0])!=0:
			highest_matches = list(set([(element[0],element[1],element[2],element[3]) for element in matches[0]]))
			if len(highest_matches)>1:
				return ("Multiple A Matches",str(highest_matches))
			else:
				return ("A",str(highest_matches[0]))
		elif matches[1]and len(matches[1])!=0:
			highest_matches = list(set([(element[0],element[1],element[2],element[3]) for element in matches[1]]))
			if len(highest_matches)>1:
				return ("Multiple B Matches",str(list(set([(element[0],element[1],element[2],element[3]) for element in matches[1]]))))
			else:
				return ("B",str(highest_matches[0]))
		elif matches[2] and len(matches[2])!=0:
			highest_matches = list(set([(element[0],element[1],element[2],element[3]) for element in matches[2]]))
			if len(highest_matches)>1:
				return ("Multiple C Matches",str(list(set([(element[0],element[1],element[2],element[3]) for element in matches[2]]))))
			else:
				return ("C",str(highest_matches[0]))
		elif matches[3] and len(matches[3])!=0:
			highest_matches = list(set([(element[0],element[1],element[2],element[3]) for element in matches[3]]))
			if len(highest_matches)>1:
				print(str(matches[3].getresult()))
				return ("Multiple D Matches",str(list(set([(element[0],element[1],element[2],element[3]) for element in matches[3]]))))
			else:
				return ("D",str(highest_matches[0]))
		elif matches[4] and len(matches[4])!=0:
			highest_matches = list(set([(element[0],element[1],element[2],element[3]) for element in matches[4]]))
			if len(highest_matches)>1:
				print(str(matches[4].getresult()))
				return ("Multiple E Matches",str(list(set([(element[0],element[1],element[2],element[3]) for element in matches[4]]))))
			else:
				return ("E",str(highest_matches[0]))

		else:
			return ("F",None)

	return ("F",None)

"""
Function: process_sample(index,pdf_path, database_name, corenlp_ptr, degrees_of_rotation,
						fp,compiled_DDMMYYYY_date_pattern,compiled_YYYYMMDD_date_pattern,compiled_MMDDYYYY_date_pattern,compiled_PHN_pat)

IDEA: main functionality of this program is excecuted within this function.
		given a path to the document for processing:
			-convert to text using libraries and pytesseract
			-process the sample using corenlp to find dates/names/numbers in the text
			-remove commas (simplifying finding dates etc)************************************************maybe remove? test it!
			-"strip" or process the dates found using CoreNLP to only include dates which could represent the DOB in a document
			-use the find_dates function to parse through the text to find sequences of characters which could represent dates.
			-try to convert all the valid_dates into datetime objects, allowing exceptions to be thrown when a field is out of bounds for valid dates
			-use the date extractor module to then parse through the text again, probably catching some dates I did not find in the previous steps
		NOTE: using only 1 or 2 of the above date finding/extracting methods lead to fewer "high rating" matches in the final output
			  Further testing should be done to determine which methods should be used, to most importantly get the most dates, but secondly improve runtime
			-open a text file corresponding to processing a given document, where the findings of this prorgam can be recorded and analyzed for future development.
			-open a connection to the postgresql database on the local device, holding all the patient records/information which is to be queried for potential matches.
			-make the queries
			-check and write the results to the file opened for this document
			-close the file
			-return the patient prediction ie: ("Match rating", (PHN,fname,lname,DOB) ) NOTE: could return multiple patient tuples if ambiguous result
Input: index = index of the sample being processed
	   pdf_path = path to the sample pdf in the form of a string
	   database_name = database name being accessed
	   corenlp_ptr = ptr to the interface for Stanford's CoreNLP engine, for NER functionality
	   degrees_of_rotation = number of degrees the pdfs should be rotated, in CCW direction
	   compiled_DDMMYYY/YYYYMMDD/MMDDYYYY_patterns = compiled regex patterns for use in identifying dates in common formats within the sample
	   compiled_PHN_pat = compiled regex pattern to recognize 10 digit PHNs in the document, potentially removing separating characters
Output: a patient_hypothesis tuple of the form (<match status>/None, <patient(s) information>/None)


"""
def process_sample(index,pdf_path, database_name, table_name, system_username, corenlp_ptr, degrees_of_rotation, fp,compiled_DDMMYYYY_date_pattern,
												compiled_YYYYMMDD_date_pattern,compiled_MMDDYYYY_date_pattern,compiled_PHN_pat):
	text = p2t.convert_pdf_to_txt(pdf_path, degrees_of_rotation)

	#per_day_num = tuple:(PERSON[], DATE[], NUMBER[])
	per_day_num = interact.annotate_ner_with_corenlp(text.replace(",",""), corenlp_ptr)
	#filep = open("converted_text_{}.txt".format(str(index)),"w")
	#filep.write(text)
	valid_dates = []
	#each of these strip_dates function calls appends each valid date match to the valid_dates list
	strip_dates(per_day_num[1],compiled_DDMMYYYY_date_pattern,valid_dates, DDMMYYYY=True, MMDDYYYY = False, YYYYMMDD = False )
	strip_dates(per_day_num[1],compiled_YYYYMMDD_date_pattern,valid_dates,DDMMYYYY= False, MMDDYYYY = False, YYYYMMDD = True)
	strip_dates(per_day_num[1],compiled_MMDDYYYY_date_pattern,valid_dates, DDMMYYYY= False,MMDDYYYY = True, YYYYMMDD = False)
	find_dates(text,compiled_DDMMYYYY_date_pattern,valid_dates, DDMMYYYY=True, MMDDYYYY = False, YYYYMMDD = False )
	find_dates(text,compiled_YYYYMMDD_date_pattern,valid_dates,DDMMYYYY= False, MMDDYYYY = False, YYYYMMDD = True)
	find_dates(text,compiled_MMDDYYYY_date_pattern,valid_dates, DDMMYYYY= False,MMDDYYYY = True, YYYYMMDD = False)
	found_datetimes=[]
	for date in valid_dates:
		try:
			if 0<int(date[1])<13 and 0<int(date[2])<32 and 1900 < int(date[0])< 2018:

				found_datetimes.append(datetime.date(int(date[0]),int(date[1]),int(date[2])))
		except Exception:
			continue

	found_datetimes = [datetime.date(int(date[0]),int(date[1]),int(date[2])) for date in valid_dates if 0<int(date[1])<13 and 0<int(date[2])<32 and 1900 < int(date[0])< 2018]
	extracted_dates = date_extractor.extract_dates(text)
	extracted_dates = [dt.date() for dt in extracted_dates if dt]
	found_datetimes+= extracted_dates
	"""
	#print("PERSON list :",str(per_day_num[0]))
	#print("CoreNLP's DATE list: ", str(per_day_num[1]))
	#print("NUMBER list: ", str(per_day_num[2]))
	#print("Regular expression's DATES list:", str(valid_dates))
	#print("Datetime.date objects: ", str(found_datetimes))
	#print("VALID PHN list: ", PHN_identifier(per_day_num[2],compiled_PHN_pat))
	#print("PATIENT HYPOTHESIS from highest frequency: " , patient_hypothesis(per_day_num[0]))
	"""

	fp.write("{}\nTest case #{} processed: ".format(str(pdf_path),index))
	fp.write("Person List: "+ str(per_day_num[0])+"\n\n")
	fp.write("CoreNLP's Date List: "+ str(per_day_num[1])+"\n\n")
	fp.write("Extracted dates with date-extractor: " + str(extracted_dates)+"\n\n")
	fp.write("Number list: "+ str(per_day_num[2])+"\n\n")
	fp.write("Verified Date List: "+ str(valid_dates)+"\n\n")
	fp.write("Valid PHN List: "+ str(PHN_identifier(per_day_num[2], compiled_PHN_pat))+"\n\n")

	db= db_interaction.make_connection_to_db(database_name, system_username)

	#####################################################################################################
	#combining the dates in this step


	PHN_vs_DOB_vs_partial_name_results =db_interaction.PHN_vs_DOB_vs_partial_name_query(db, PHN_identifier(per_day_num[2],compiled_PHN_pat), found_datetimes,per_day_num[0], table_name)
	PHN_vs_DOB_results = db_interaction.PHN_vs_DOB_query(db, PHN_identifier(per_day_num[2],compiled_PHN_pat), found_datetimes, table_name)
	PHN_vs_partial_name_results = db_interaction.PHN_vs_partial_name_query(db, PHN_identifier(per_day_num[2],compiled_PHN_pat), per_day_num[0], table_name)
	DOB_vs_partial_name_results = db_interaction.DOB_vs_partial_name_query(db, found_datetimes, per_day_num[0], table_name)

	#This patient prediction is the variable which should be used to determine where the sample gets filed
	################################################################################################################################################## THERES A NONE HERE TO REPRESENT POSSIBLE BOTTOM UP MATCHES
	patient_prediction_result = patient_hypothesis((PHN_vs_DOB_vs_partial_name_results,PHN_vs_DOB_results,PHN_vs_partial_name_results,DOB_vs_partial_name_results,None))

	fp.write("\nPatient Hypothesis: " + str(patient_prediction_result)+" for {}".format(str(pdf_path)))
	fp.write("\nA: Matches crossreferencing the PHN vs DOB vs partial found names\n" + str(PHN_vs_DOB_vs_partial_name_results))
	fp.write("\nB: Matches crossreferencing the PHN vs DOB:\n" + str(PHN_vs_DOB_results))
	fp.write("\nC: Matches crossreferencing the PHN vs partial found names:\n" + str(PHN_vs_partial_name_results))
	fp.write("\nD: Matches crossreferencing the DOB vs partial found names:\n" + str(DOB_vs_partial_name_results))
	fp.write("\n Matches found using only DOB: " + str(db_interaction.DOB_query(db,found_datetimes,table_name)))
	fp.write("\n\n\n TEXT EXTRACTED: " + text)
	fp.close()
	return patient_prediction_result


"""
FUNCTION: main()
DESCRIPTION: -basically a function which runs to process the arguments, and generate the whole list of paths "pdf_list" of the specified folder by --inf
			 -Contains a loop which interates through every pdf_path string and tries to process_sample()
			 -allows for the rotation of the documents if specified.

INPUT: cmd line args:
		--inf an already existing folder which contains subfolders and the documents to be processed (only considering .pdf files)
		--db the name of the postgresql database where patient records are stored
		--t the name of the relation/table in the database corresponding to patient records
		--of the folder where the text file results are stored alongside a copy of the pdf processed for each
		--u system username used to log into the postgresql database. Needs to have create/drop table, select priveleges in the db
OUTPUT: generates files for each of the documents processed, and stores them in the folder specified by --of

"""
def main():
	ap = argparse.ArgumentParser()
	ap.add_argument("--inf","--inputfolder", required = True)
	ap.add_argument("--db","--database",required =True)
	ap.add_argument("--t","--tablename", required = False)
	ap.add_argument("--of", "--outputfolder", required=False)
	ap.add_argument("--u","--systemusername",required=True)

	args = ap.parse_args()
	start_time = time.time()


	#from stack overflow : https://stackoverflow.com/questions/3964681/find-all-files-in-a-directory-with-extension-txt-in-python
	#getting the names of all the files stored within that folder

	pdf_list = get_pdf_paths(str(args.inf))
	database_name = args.db
	system_username = args.u
	#Setting up the regex patterns needed for number and date extractionn
	PHN_pattern = r'(\d{10})|((?:\d[^\n\d]?){10}(?!\d))'
	DDMMYYYY_date_pattern = r'((?<!\d\d)(\d{1,2})[^\na-zA-Z0-9]+(\d{1,2}|January|February|March|April|May|June|July|August|September|October|November|December|Jan|Feb|Mar|Apr|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec)[^\na-zA-Z0-9]+(\d{2,4}))'
	YYYYMMDD_date_pattern = r'((\d{2,4})[^\n\w]+(\d{1,2}|January|February|March|April|May|June|July|August|September|October|November|December|Jan|Feb|Mar|Apr|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec)[^\n\w]+(\d{1,2}))'
	MMDDYYYY_date_pattern = r'((\d{1,2}|January|February|March|April|May|June|July|August|September|October|November|December|Jan|Feb|Mar|Apr|Jun|Jul|Aug|Sep|Sept|Oct|Nov|Dec)[^\na-zA-Z0-9]+(\d{1,2})[^\na-zA-Z0-9]+(\d{2,4}))'
	compiled_DDMMYYYY_date_pattern = re.compile(DDMMYYYY_date_pattern, re.IGNORECASE)
	compiled_YYYYMMDD_date_pattern = re.compile(YYYYMMDD_date_pattern,  re.IGNORECASE)
	compiled_MMDDYYYY_date_pattern = re.compile(MMDDYYYY_date_pattern, re.IGNORECASE)
	compiled_PHN_pat = re.compile(PHN_pattern)


	corenlp_ptr = interact.init_corenlp()
	runtime_fp = open("Test_Results/Runtime.txt", "w")

	for index,pdf_path in enumerate(pdf_list):

		#if index<19:
		#	continue
		print("processing sample #:",str(index))
		fp = open("{}/{}.txt".format(args.of,index), "w")
		copyfile(pdf_path, "Test_Results/{}.pdf".format(index))
		degrees_of_rotation = 0
	#	try:

		patient_prediction_result = process_sample(index, pdf_path, database_name,args.t, system_username, corenlp_ptr,  degrees_of_rotation, fp,compiled_DDMMYYYY_date_pattern,compiled_YYYYMMDD_date_pattern,compiled_MMDDYYYY_date_pattern,compiled_PHN_pat )
		attempt=1
		degrees_of_rotation+=180

		fp.close()
		gc.collect()
		print("Patient Prediction Rating: ", str(patient_prediction_result[0]))

		#if we were unable to find any matches at all, then the document may need to be rotated 180 degrees, so do it and try again
"""		while patient_prediction_result[0]=="F" and attempt<2:
			print("Rotation Attempt # {}. Failed to find a patient match, rotating and retrying... current rotation = {}".format(str(attempt),str(degrees_of_rotation)))
			fp.write("\n\n\nFailed to find a database match. Attempting to rotate the pdf and repeat the process\n\n")
			patient_prediction_result = process_sample(index, pdf_path, database_name, corenlp_ptr, degrees_of_rotation, fp, compiled_DDMMYYYY_date_pattern,compiled_YYYYMMDD_date_pattern,compiled_MMDDYYYY_date_pattern,compiled_PHN_pat)
			degrees_of_rotation +=90

			if attempt== 2:
				degrees_of_rotation -=270
			attempt+=1
"""


if __name__ == "__main__":
	main()

